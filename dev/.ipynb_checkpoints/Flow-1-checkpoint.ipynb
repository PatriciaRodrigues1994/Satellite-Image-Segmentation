{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools import mask as cocomask\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import random\n",
    "import os\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
    "\n",
    "import dataset.transform_and_augment as trans_aug\n",
    "import os\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "from dataset.dataset import TrainImageDataset, TestImageDataset\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the working dirctory\n",
    "project_dir = \"/home/webwerks/patricia/my-projects/github/Segmentation\"\n",
    "os.chdir(project_dir)\n",
    "\n",
    "data_directory = \"data/\"\n",
    "annotation_file_template = \"{}/{}/annotation{}.json\"\n",
    "\n",
    "TRAIN_IMAGES_DIRECTORY = \"data/train/images\"\n",
    "TRAIN_ANNOTATIONS_PATH = \"data/train/annotation.json\"\n",
    "TRAIN_ANNOTATIONS_SMALL_PATH = \"data/train/annotation-small.json\"\n",
    "\n",
    "VAL_IMAGES_DIRECTORY = \"data/val/images\"\n",
    "VAL_ANNOTATIONS_PATH = \"data/val/annotation.json\"\n",
    "VAL_ANNOTATIONS_SMALL_PATH = \"data/val/annotation-small.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=31.72s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "train_coco = COCO(os.path.join(TRAIN_ANNOTATIONS_PATH))\n",
    "X_train = train_coco.getImgIds(catIds=train_coco.getCatIds())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img_resize = (300, 300)  # The resize size of the input images of the neural net\n",
    "output_img_resize = (300, 300)  # The resize size of the output images of the neural net\n",
    "\n",
    "batch_size = 3\n",
    "epochs = 50\n",
    "threshold = 0.5\n",
    "validation_size = 0.2\n",
    "sample_size = None  # Put 'None' to work on full dataset or a value between 0 and 1\n",
    "\n",
    "# -- Optional parameters\n",
    "threads = cpu_count()\n",
    "use_cuda = torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'cocodataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-11ee789f7304>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m train_ds = TrainImageDataset(X_data = X_train, cocodataset = train_coco, y_data = None, input_img_resize = input_img_resize, \n\u001b[0;32m----> 3\u001b[0;31m                              output_img_resize = output_img_resize, X_transform=trans_aug.augment_img)\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'cocodataset'"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "train_ds = TrainImageDataset(X_data = X_train, cocodataset = train_coco, y_data = None, input_img_resize = input_img_resize, \n",
    "                             output_img_resize = output_img_resize, X_transform=trans_aug.augment_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size,\n",
    "                          sampler=RandomSampler(train_ds),\n",
    "                          num_workers=threads,\n",
    "                          pin_memory=use_cuda)\n",
    "\n",
    "valid_ds = TrainImageDataset(X_valid, y_valid, input_img_resize, output_img_resize,\n",
    "                             threshold=threshold)\n",
    "valid_loader = DataLoader(valid_ds, batch_size,\n",
    "                          sampler=SequentialSampler(valid_ds),\n",
    "                          num_workers=threads,\n",
    "                          pin_memory=use_cuda)\n",
    "\n",
    "print(\"Training on {} samples and validating on {} samples \"\n",
    "      .format(len(train_loader.dataset), len(valid_loader.dataset)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
